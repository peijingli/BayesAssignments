---
title: 'Assignment 2, Question 3 MAST90125: Bayesian Statistical Learning'
header-includes:
   - \usepackage{bm}
   - \usepackage{amsmath}
output: 
  pdf_document:
    number_sections: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Due: Friday 20 September 2019**  
\vspace{5 mm}

**There are places in this assignment where R code will be required. Therefore set the random seed so assignment is reproducible.**

```{r}
set.seed(742072)  #Please change random seed to your student id number.
```

## Question Three (18 marks)

A group of 453 Bangladeshi women in 5 districts were asked about contraceptive use. The response variable *use* is an indicator for contraceptive use (coded N for no and Y for yes). Other covariates of interest are categorical variables for geographical location *district* (5 levels), and *urban* (2 levels), and number of living children *livch* (4 levels), and the continuous covariate for standardised age *age*.A random intercept for the district was suggested. This suggested the following model should be fitted,

\[ \bm \theta = {\bf Z}{\bf u} + {\bf X}{\bm \beta},  \]

where $\bm \theta$ is a link function, $\bf Z$ is an indicator variable for district, $\bf u$ is a random intercept with prior $p({\bf u}) = \mathcal{N}({\bf 0},\sigma^2_u{\bf I})$, and ${\bf X}$ is a design matrix for fixed effects $\bm \beta$, where $\bm \beta$ includes the coefficients for the intercept, urban status, living children, and age. 

Data can be downloaded from LMS as \texttt{Contraceptionsubset.csv}.

a) Fit a generalised linear mixed model assuming a logistic link using \texttt{Stan}. The R and stan code below covers the following steps.

\begin{itemize}
\item Importing the data.
\item Constructing design matrices.
\item Provides code to go into the stan file.
\item Running stan in R. This assumes your stan file is called *logitmm.stan*, and that you will run the sampler for 2000 iterations and 4 chains.
\end{itemize}

Note that provided code assumes everything required is located in your working directory in R.

```{r, eval = FALSE}
#Step one: Importing data,  constructing design matrices and calculating matrix dimensions.
dataX= read.csv("Contraceptionsubset.csv",header=TRUE)

n<-dim(dataX)[1]
Z    = table(1:n,dataX$district)     #incidence matrix for district
Q    = dim(Z)[2]
D1   = table(1:n,dataX$livch) #Dummy indicator for living children
D2   = table(1:n,dataX$urban) #Dummy indicator for urban status

#fixed effect design matrix 
X    = cbind(rep(1,n),dataX$age,D1[,-1],D2[,-1])
P    = dim(X)[2]
y    = rep(0,n)
y[dataX$use %in% 'Y'] = 1

```

```{r results="hide", eval=FALSE}
library(rstan)
logistic.mm <-stan(file="logitmm.stan",data=c('Z','X','y','n','P','Q'),iter=2000,chains=4)
print(logistic.mm)
```

 
Note that in Stan, defaults for burn-in (warm-up) is one half of all iterations in stan, and no thinning. Note the code is written using the stan file and csv is in your working directory. Use the \texttt{print} function to report posterior means, standard deviations, 95 \% central credible intervals and state from the output whether you believe the chains have converged. Also report the reference categories for  *urban* and *livch*.




b) An alternative to the logit link when analysing binary data is the probit. The probit link is defined as,

\begin{eqnarray}
y_i &=& \begin{cases} 1 & \text{if $z_i \geq 0$}\\ 
0 & \text{if $z_i < 0$}\\ 
\end{cases} \nonumber \\
z_i &=& {\bf x}_i'\bm \beta + \epsilon_i, \quad \epsilon \sim \mathcal{N}(0,1). \nonumber 
\end{eqnarray}

In lecture 14, we showed how by letting $z_i$ be normal, probit regression can be fitted using a Gibbs sampler, but to do so, it requires the ability to sample from a truncated normal defined on either $(-\infty,0)$ (if $y_i = 0$) or $(0,\infty)$ (if $y_i = 1$). Check by comparing the empirical and the true density that a modified version of the inverse cdf method can be used to produce draws from a truncated normal. Do this for the case where $x \in (0,\infty)$ and $x \in (-\infty,0)$ with parameters $\mu=0.5$ and $\sigma=1$.

Hints: If $y$ is drawn from a truncated normal with lower bound $a$, upper bound $b$ and parameters $\mu, \sigma^2$ then then $p(y|\mu,\sigma^2,a,b)$ is 

\[ \frac{\frac{1}{\sqrt{2\pi\sigma^2}}e^{-(y-\mu)^2/2}}{\int_{-\infty}^b \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(y-\mu)^2/2} dy - \int_{-\infty}^a \frac{1}{\sqrt{2\pi\sigma^2}}e^{-(y-\mu)^2/2} dy}, \]

which in \texttt{R} means the truncated normal density can be written as 

\begin{footnotesize}
\begin{verbatim}
dnorm(x,mean=mu,sd=sigma)/(pnorm(b,mean=mu,sd=sigma)-pnorm(a,mean=mu,sd=sigma))
\end{verbatim}
\end{footnotesize}

The inverse cdf method involves drawing $v$ from $U(0,1)$ so that $x \sim p(x)$ can be found solving $x=F^{-1}(x)$, where $F$ is the cdf. If the only change compared to drawing from a normal distribution is truncation, think about what happens to the bounds of the uniform distribution. 

In order to sample from a trucated normal with $y\in(a,b]$, denote the CDF of Normal Random variable $y$ as 
\[\Phi(y) = \frac{1}{\sqrt{2\pi\sigma^2}}\int_{-\infty}^{y} \exp{-\frac{(x-\mu)^2}{2\sigma^2}} \, dx, \]

Then, the CDF of the truncated Normal Random variable $y$ ,denoted as $\hat{\Phi}$, is 

\[\hat{\Phi}(y) = \frac{\Phi(y)-\Phi(a)}{\Phi(b)-\Phi(a)} \in [0,1]\]. 

Now, we can draw a random variable $u$ from Uniform $(0,1)$ distribution such that 

\begin{align*}
  \hat{\Phi}(y) &= u\\
  \Phi(y) &= u(\Phi(b)-\Phi(a))+\Phi(a)\\
  y &= \Phi^{-1}(u(\Phi(b)-\Phi(a))+\Phi(a))
\end{align*}
where $\Phi^{-1}(\cdot)$ is the inverse CDF of the Normal distribution with mean $mu$ and variance $\sigma^2$
and we can get desired draw from a trucated Normal distribution of $N(\mu,\sigma^2)$ with bound $(a,b]$.

First, construct function for sampling truncated normal for both ranges. 
```{r}
trunc<-function(range,mean_trunc,sd,npar){
  if(range==1){
    sigma<-1
    mu<-(-1*mean_trunc)
    u<-runif(npar,0,1)
    area<-u*(pnorm(0,mean=mu,sd=sigma)-0)
x<-qnorm(area,mean=mu,sd=sigma)
x<-(-1)*x
  }
  if(range==0){
     sigma<-1
    mu<-mean_trunc
u<-runif(npar,0,1)
area<-u*(pnorm(0,mean=mu,sd=sigma)-0)
x<-qnorm(area,mean=mu,sd=sigma)
  }
   return(x) 
}
  
```

Now, we impliement the code to test the method 
1. $x\in[0,+\infty)$
```{r}
z<-trunc(1,0.5,1,1000000)
hist(z,freq=FALSE,breaks=1000,main="density of truncated normal")

```
2. $xin(-\infty,0]$
```{r}
z<-trunc(0,0.5,1,1000000)
hist(z,freq=FALSE, breaks=1000,main="density of truncated normal")
```
3. Check extreme cases:
```{r}
z<-trunc(1,-25,1,1)
z2<-trunc(0,25,1,1)
print(z)
print(z2)
```

c) Implement a Gibbs sampler to fit the same mixed model as fitted in Stan in a), but now with a probit link. As before, fit 4 chains, each running for 2000 iterations, with the first 1000 iterations discarded as burn-in. Perform graphical convergence checks and Gelman-Rubin diagnostics. Report posterior means, standard deviations and 95 \% central credible intervals for $\sigma, \bm \beta, {\bf u}$ by combining chains. 

```{r}
contraceptive_Gibbs<-function(iter,Z,X,y,burnin,tauu_0,a.u,b.u){
  n   <-length(y) #no. observations
  p   <-dim(X)[2] #no of fixed effect predictors.
  q   <-dim(Z)[2] #no of random effect levels
  
  tauu<-tauu_0
  beta0<-rep(1,p) #initialize coefficients
  taue<-1
  z <- rep(0,n)
  #starting value for u.
  u0   <-rnorm(q,0,sd=1/sqrt(tauu))
  
  betau<-c(beta0,u0)
  
  #Building combined predictor matrix.
  W<-cbind(X,Z)            #for the joint conditional posterior for b,u
  WTW <-crossprod(W)
  library(mvtnorm)
  
  #storing results.
  par <-matrix(0,iter,p+q+1)  #p beta coefficient, q u coefficients and 1 precision coefficient.
  
  #Create modified identity matrix for joint posterior.
  I0  <-diag(p+q)#identity matrix
  diag(I0)[1:p]<-0
  
  for(i in 1:iter){
    #Conditional posteriors.
  tauu <-rgamma(1,a.u+0.5*q,b.u+0.5*sum(u0^2)) #sample tau_u
    #Updating component of normal posterior for beta,u
    Prec <-WTW + tauu*I0/taue
    
    #sample z from truncated normal
    mean_trunc<-X%*%betau[1:p]+Z%*%betau[(p+1):(p+q)] #truncated mean
    
    for(j in 1:n){
      z[j]<-trunc(y[j],mean_trunc[j],sigma<-1,1)
    }
    #return a vector of z

    P.mean <- solve(Prec)%*%crossprod(W,z)
    P.var  <-solve(Prec)/taue
    
    betau <-rmvnorm(1,mean=P.mean,sigma=P.var) #sample beta, u
    betau <-as.numeric(betau)
    err   <- z-W%*%betau
    #storing iterations for beta, u, and standard deviation of e, u.
    par[i,]<-c(betau,1/sqrt(tauu))
    u0<-betau[(p+1):(p+q)]  #extracting u so we can update tau_u.
  }
  
par <-par[-c(1:burnin),] #removing initial iterations
colnames(par)<-c(paste('beta',1:p,sep=''),paste('u',1:q,sep=''),'sigma_u')  
 return(par) 
}
```
Now, input data and create chains

```{r}

chain_1<-contraceptive_Gibbs(2000,Z,X,y,1000,tauu_0=1,a.u=-.5,b.u=0)
chain_2<-contraceptive_Gibbs(2000,Z,X,y,1000,tauu_0=3,a.u=-.5,b.u=0)
chain_3<-contraceptive_Gibbs(2000,Z,X,y,1000,tauu_0=2,a.u=-.5,b.u=0)
chain_4<-contraceptive_Gibbs(2000,Z,X,y,1000,tauu_0=2.4,a.u=-.5,b.u=0)
library(coda)
ml1<-as.mcmc.list(as.mcmc((chain_1)))
ml2<-as.mcmc.list(as.mcmc((chain_2)))
ml3<-as.mcmc.list(as.mcmc((chain_3)))
ml4<-as.mcmc.list(as.mcmc((chain_4)))
estml<-c(ml1,ml2,ml3,ml4)
gelman.diag(estml)[[1]]

#effective sample size.
effectiveSize(estml) 

probit_means<-as.numeric(colMeans(rbind(chain_1,chain_2,chain_3,chain_4)) )

```
Posterior means: 
```{r}
probit_means
```
Plots of convergence:
```{r}
plot(mcmc.list(estml))
```



d) For the co-efficients $\bm \beta$, $\bf u$, calculate the mean of the ratio of the posterior means $\bm \beta_{i,\text{logit}}/\bm \beta_{i,\text{probit}}, {\bf u}_{i,\text{logit}}/{\bf u}_{i,\text{probit}}$ obtained when fitting the logistic mixed model and the probit mixed model. To do this, you will need to apply the \texttt{extract} function to the stan model object. Once calculated, multiply the iterations obtained assuming a probit link by this constant and compare to the iterations obtained assuming a logit link.   

```{r}
sample_stan<-rstan::extract(logistic.mm)

sample_beta_mean<-colSums(as.matrix(sample_stan$beta))/dim(as.matrix(sample_stan$beta))[1]

sample_u_mean<-colSums(as.matrix(sample_stan$u))/dim(as.matrix(sample_stan$u))[1]

sample_sigma_mean<-colSums(as.matrix(sample_stan$sigma))/dim(as.matrix(sample_stan$sigma))[1]

par_mean<-c(sample_beta_mean,sample_u_mean)

ratio_par<-par_mean/probit_means[1:11]

mean_ratio_par<-mean(ratio_par)

```
the mean of ratios is
```{r}
mean_ratio_par
```
after multiply by the ratio, the posterior means under probit regression are:
```{r}
mean_ratio_par*probit_means
```
which are similar to the posterior means under logistic link
```{r}
par_mean
```


e) The logistic link can be written in the same way as the probit link, but instead of $e_i\sim \mathcal{N}(0,1)$, the error term is $e_i \sim \text{Logistic}(0,1)$. By evaluating the standard normal and logistic inverse cdfs and superimposing the line $y = mx$ where $m$ is the posterior ratio, do you think the results in d) were surprising.
```{r}
x<-rnorm(10000,mean=0,sd=1)
y<-rlogis(10000,location=0,scale=1)
x_line<-seq(-5,5,by=0.06)
y_line<-mean_ratio_par*x_line
Ninv<-qnorm(x_line,mean=0,sd=1)
Linv<-qlogis(x_line,0,1)
qqplot(Ninv,Linv,type='l')
lines(x_line,y_line,col='red')
```



